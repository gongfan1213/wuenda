# 上下文工程（Context Engineering）详解及实践策略

## 什么是上下文工程？
上下文工程是一门**艺术与科学**，核心是在智能体（Agent）运行的每一步，向其上下文窗口（Context Window）中填充“恰到好处”的信息。这一概念由Shopify的Toby提出，后经Karpathy完善定义——它类比于操作系统对内存（RAM）的管理：大语言模型（LLM）如同CPU，上下文窗口如同有限的工作内存，而上下文工程就是决定“哪些信息应被放入内存”的规则体系。


## 为什么智能体需要上下文工程？
智能体的两大特性使其对上下文管理要求更高：
- **长任务处理**：复杂任务需多轮交互，上下文会随步骤累积。
- **工具调用依赖**：工具返回结果会持续占用上下文空间。

若上下文管理不当，会引发“上下文失效”问题，包括：
- **上下文污染**：无关信息干扰决策。
- **注意力分散**：关键信息被冗余内容稀释。
- **信息冲突**：不同来源的信息矛盾导致混淆。
- **幻觉扩散**：错误信息被后续步骤放大。


## 上下文工程的四大核心策略
根据信息处理方式，上下文工程可分为四大类，以下结合主流智能体案例具体说明：


### 一、写入上下文（Writing Context）
**定义**：将信息存储在上下文窗口之外，供智能体后续使用（类似人类“记笔记”或“长期记忆”）。

#### 1. 临时笔记（Scratch Pad）
- **作用**：存储任务执行中的临时信息（如计划、中间结果），仅在当前会话有效。
- **案例**：Anthropic的多智能体研究员模型会将研究计划写入临时存储，避免因上下文窗口容量（如20万token）限制而丢失。
- **实现方式**：可存储为文件、运行时状态对象（如LangGraph的State）等。

#### 2. 长期记忆（Memories）
- **作用**：跨会话存储信息（如用户偏好、历史交互），用于长期行为优化。
- **案例**：
  - ChatGPT的记忆功能会记录对话历史。
  - Generative Agents通过过去交互合成记忆，用于模拟持续行为。
- **特点**：需动态更新（如新信息覆盖旧信息），且支持选择性调用。


### 二、选择上下文（Selecting Context）
**定义**：从存储中筛选相关信息，按需传入上下文窗口（避免无关信息占用空间）。

#### 1. 记忆类型的选择性调用
人类记忆分为语义记忆（事实）、情景记忆（经验）、程序记忆（技能），智能体可类比调用：
- **程序记忆**：如代码智能体的“规则文件”（Style Guidelines），定义工具使用规范。
- **语义记忆**：通过向量数据库或知识图谱检索事实（如产品参数）。
- **情景记忆**：调用历史案例（Few-Shot Examples）指导当前任务。

#### 2. 工具的选择性加载
- **问题**：智能体难以处理大量工具（研究显示，工具数量超过30个时性能下降，100个时可能失效）。
- **解决方案**：对工具描述进行嵌入（Embedding），通过语义相似度检索相关工具（如用RAG技术筛选API）。

#### 3. 知识的精准检索（RAG技术）
- **核心**：从海量数据中提取与当前任务相关的知识。
- **进阶实践**：
  - 代码智能体（如Cursor、Windsurf）会按语义边界分割代码块（而非随机分割）。
  - 结合向量检索、知识图谱和LLM排序，提升检索可靠性。


### 三、压缩上下文（Compressing Context）
**定义**：保留关键信息，减少冗余内容（降低token消耗，避免信息过载）。

#### 1. 总结（Summarization）
- **全轨迹总结**：如Claude在会话接近20万token上限时，自动压缩历史交互。
- **局部总结**：
  - Anthropic多智能体对已完成工作片段进行总结。
  - Cognition在智能体与子智能体交互时，用总结传递核心信息。

#### 2. 修剪（Trimming）
- **规则修剪**：保留最近的N条消息（适用于对话类智能体）。
- **智能修剪**：用LLM判断信息重要性，移除无关内容（如过滤重复的工具调用结果）。


### 四、隔离上下文（Isolating Context）
**定义**：拆分信息到不同“容器”，避免相互干扰（提升复杂任务处理能力）。

#### 1. 多智能体架构
- **原理**：每个子智能体拥有独立上下文窗口，并行处理子任务，整体提升系统的总信息处理量。
- **案例**：
  - OpenAI的Swarm库：按“关注点分离”设计，不同智能体负责工具调用、结果分析等。
  - Anthropic多智能体研究员：子智能体分别探索问题的不同维度，最终汇总结论。

#### 2. 沙箱（Sandbox）隔离
- **作用**：将token密集型数据（如图像、音频）存储在沙箱中，仅向LLM返回关键元信息（如变量名、输出结果）。
- **案例**：Hugging Face的代码智能体在沙箱中执行代码，仅将必要结果传回LLM。

#### 3. 状态对象分区
- **实现**：用结构化状态对象（如Pydantic模型）拆分信息，例如：
  - `messages`字段：存储实时交互内容（始终传入上下文）。
  - `history`字段：存储历史数据（仅在需要时调用）。


## LangGraph对上下文工程的支持
LangGraph作为智能体编排框架，通过以下特性支持上述策略：

| 策略         | 核心支持能力                                                                 |
|--------------|------------------------------------------------------------------------------|
| 写入上下文   | 状态对象（State）支持临时存储；内置长期记忆组件支持跨会话存储。               |
| 选择上下文   | 可在任意节点检索状态或记忆；支持向量检索工具（如Big Tool）筛选工具/知识。     |
| 压缩上下文   | 提供摘要和修剪工具；允许在节点中自定义后处理逻辑（如压缩工具返回结果）。     |
| 隔离上下文   | 支持多智能体架构（Supervisor/Swarm模式）；兼容沙箱环境（如E2B）；状态对象可按 schema 分区。 |

此外，LangSmith可追踪token使用，LangChain评估工具可验证上下文工程的效果（如压缩后是否影响任务准确率）。


## 总结
上下文工程是智能体开发的核心挑战，其核心目标是“在有限的上下文窗口中，让智能体始终获得最相关的信息”。四大策略各有侧重：
- **写入**：解决“信息保存”问题。
- **选择**：解决“信息相关性”问题。
- **压缩**：解决“空间限制”问题。
- **隔离**：解决“信息干扰”问题。

随着智能体复杂度提升，这些策略将结合得更加紧密（如“先选择再压缩”“隔离后选择性调用”）。实践中需结合具体场景（如任务类型、工具数量、数据规模）灵活调整。

https://blog.langchain.com/context-engineering-for-agents/


https://www.youtube.com/watch?v=4GiqzUHD5AA
