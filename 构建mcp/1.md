# 1
```
Transcript
0:01 Welcome to MCP: Build
0:04 Rich-Context AI Apps with Anthropic built in partnership with Anthropic.
0:08 In this course, you'll learn the core concepts of MCP
0:11 and how to implement it in your AI application.
0:15 The Model Context Protocol, or MCP, is an open protocol
0:19 that standardizes how your LLM applications can get access to context
0:23 in terms of tools and data resources
0:26 based on the client-server architecture.
0:29 It defines how communication takes place between an MCP client
0:33 hosted inside your own LLM application, and an MCP server
0:36 that exposes tools and data resources and prompt templates to your application.
0:41 Since Anthropic launched MCP in November of 2024,
0:45 the MCP ecosystem has been growing really rapidly.
0:48 I'm delighted that the instructor for this course is Elie Schoppik,
0:52 who is Head of Technical Education at Anthropic.
0:55 Thanks, Andrew. I'm excited to teach this course with you.
0:58 MCP originated as part of an internal project
1:01 where we recognized an opportunity to extend the capabilities of Claude Desktop
1:05 so that it can interact with local file systems and other external systems.
1:10 We found the protocol we developed was useful in many AI applications,
1:13 with similar needs. To make this available to more developers,
1:17 we published the specification
1:18 and opened its development to the open source community.
1:21 The MCP ecosystem includes a growing number of MCP service
1:25 developed by the open source community, as well as by Anthropic's MCP team.
1:31 MCP is model agnostic and is designed to be easy
1:34 to plug into multiple applications.
1:36 Say you're building a research assistant agent,
1:39 and you'd like for this agent to interact with your GitHub repos, read notes
1:42 from your Google Drive documents, maybe create a summary stored
1:46 in your local system. Instead of you writing your own custom LLM tools,
1:50 you can connect your agent to the GitHub, Google Drive and File System service,
1:55 which will provide the tool or the API call
1:58 definitions and also handle the tool execution.
2:02 Elie will walk you through the details of the MCP protocol.
2:05 We'll first dive into the details of the MCP client-server architecture.
2:09 You'll then work on a chatbot application to make it MCP compatible.
2:14 You'll build and test an MCP server and connect your chatbot to it.
2:18 Your MCP
2:18 server will provide tools, prompt templates, and resources to your chatbot.
2:23 You'll also connect your chatbot to other trusted third-party servers
2:27 to extend its capabilities.
2:29 You'll then re-use your MCP server and connect it
2:31 to other MCP applications like Claude Desktop.
2:35 Finally, you'll learn how you can deploy your MCP server remotely.
2:39 I'd like to thank from DeepLearning.AI,
2:41 Hawraa Salami, who had contributed to this course.
2:45 MCP is a really important technology
2:47 that's making it much easier for LLM application developers
2:50 to connect the systems to many tools and data resources.
2:54 And for teams building tools or providing data,
2:57 it is also making it much easier
2:58 to make what they build available to many developers.
3:02 So this is a technology worth learning about.
3:05 The next video goes through why connecting LLM applications
3:09 to resources had been so difficult before, and how MCP addresses this.
3:14 So, please go on to the next video to learn more.
```
# 2
```
Transcript
0:02 In this first lesson,
0:03 we'll go through how MCP makes AI development less fragmented
0:07 and how it standardizes
0:08 connections between AI applications and external data sources.
0:13 Let's go.
0:14 To answer the question why MCP or why the Model Context protocol?
0:18 We like to say the models are only as good as the context provided to them.
0:22 You can have an incredibly intelligent model at the frontier,
0:26 but if it doesn't have the ability to connect to the outside world and pull
0:30 in the data and context necessary, it's not as useful as it can possibly be.
0:35 The Model Context Protocol is an open-source protocol
0:38 that standardizes how your large language model
0:41 connects and works with your tools and data sources.
0:44 The idea here is not to reinvent the wheel and how we do things like tool use,
0:49 but instead to standardize the way that our AI applications connect with data
0:54 sources. The same way that we standardize
0:56 how web applications communicate with back ends and other systems
1:00 using REST, where we specify the protocol and statelessness and so on,
1:04 we're trying to achieve the same thing with the Model Context Protocol.
1:08 Everything that you're going to see with MCP can be done without MCP,
1:12 but as we think about a world in which many different models communicate
1:16 with many different data sources, and even with each other,
1:20 we want to make sure that we're speaking the same language.
1:23 We want to standardize how our AI applications interact
1:26 with external systems, instead of building the same integration
1:30 for a different data source
1:31 over and over and over again, depending on the model or the data source,
1:35 we're instead going to build once and use everywhere.
1:38 The Model Context Protocol borrows a lot of its ideas
1:42 from other protocols that aim to achieve similar kind of ideas.
1:45 For example, LSP, or the Language Server Protocol developed in 2016
1:50 by Microsoft, standardizes how integrated development
1:53 environments interact with language-specific tools.
1:57 When you create extensions for particular languages
2:00 for particular development environments, you don't want to have to write that over
2:03 and over again for all of those development environments.
2:06 So while MCP is very novel and what it's trying to do,
2:09 it stands on the shoulders
2:10 of many other protocols and ideas around standardization.
2:14 Let's go show a quick demo where with just a few lines of code,
2:17 we can bring in context to our AI application.
2:20 On the left-hand side here, I'm using Claude Desktop, and I'm asking
2:23 a question about retrieving some issues from a GitHub repository.
2:27 On the right we can see this GitHub repository.
2:29 And immediately through natural language I'm able to talk to this data source.
2:34 This is the power of MCP.
2:36 I have connected to an MCP server that's providing data necessary
2:40 from GitHub, and I'm also connected
2:42 to another MCP server for Asana, a popular project management tool.
2:46 What I'm doing here is reading data from GitHub, and then I'm asking
2:50 to triage particular issues and assign tickets in Asana.
2:53 So I am reading from one data source and writing to another.
2:56 We can see here in this interface there there's a human in the loop
3:00 verifying the actions that I want to take with just very little code,
3:03 I'm now communicating with external data sources with ease.
3:07 This idea of being able to use MCP with any model provider
3:11 completely open source, allows for seamless integration
3:15 with different models and different data sources.
3:17 We can see here I've created these tasks.
3:19 Things are updating for me in the browser, and I can now continue
3:23 to use natural language to iterate on this task I have here.
3:26 I'm going to assign a task to an individual.
3:28 I'm going to see that get updated and through the use
3:31 of a very intelligent model,
3:33 in this case, 3.5 Sonnet, a few tools provided by MCP,
3:36 and an environment to run this over and over again,
3:39 we're actually taking a look at a very lightweight agent to power
3:42 this application.
3:43 Like I mentioned, everything you could do with MCP, you could do without.
3:47 But here's what it starts to look like.
3:49 As you build these integrations where do you store your tools?
3:52 Where do you store custom prompts that you have?
3:55 Where do you store that data access layer and authentication logic?
3:58 We found ourselves and for many different teams,
4:00 repeating the wheel over and over and over again, many different AI applications,
4:05 talking to a similar data source but written in a different way. With MCP,
4:09 not only is this model agnostic, it's completely open source,
4:13 so these tools and data connectivity are provided to you
4:16 by the open source community, or you can build them yourself. With MCP,
4:20 we shift the burden of responsibility and we separate our concerns
4:24 in a really clean fashion.
4:25 We build or use MCP compatible applications
4:29 and connect to many different servers for the particular kind of data access
4:33 that we need.
4:34 We can have servers for data stores, for customer relationship management tools
4:38 like HubSpot or Salesforce, even servers for things like version control.
4:42 And the aim here is to use natural language to talk to these data stores
4:47 without having to write all that logic ourselves. With MCP,
4:50 the beauty of the server is that it's also reusable
4:53 across many different applications.
4:55 As we're going to see, there are reference servers
4:57 that we can use or servers that we can even build internally
5:00 and share amongst many different applications that we build.
5:04 We might build a MCP server or use one for Google Drive,
5:07 and depending on the application that we're building,
5:10 that could be an AI assistant or agent or desktop application
5:13 as long as it is MCP compatible,
5:15 we can go and use that server and whatever else we want.
5:19 You can let your imagination really start to carry you
5:21 with all the different data access that you can bring in to your application,
5:25 with minimal code and effort. With MCP,
5:28 there are lots of wins for many different audiences.
5:30 For application developers, connect to an MCP
5:33 server with very little work. For API developers,
5:36 build the MCP server once and adopt it everywhere. For users of AI applications,
5:42 the idea behind MCP can be abstracted away quite a bit,
5:46 so that you can bring a URL for an MCP server and simply
5:50 have the data access that you need brought into your application.
5:53 For enterprises and large organizations, you can think of the benefits
5:56 of separating your concerns
5:58 and building standalone integrations that different teams can use.
6:01 As you might be aware, the MCP ecosystem is growing fast.
6:05 We're seeing development
6:06 not only from large companies, but also startups at the frontier.
6:10 And we're seeing many, many, many different servers
6:12 being built privately and in the open source community.
6:15 The SDK or software development kits that we have to power MCP
6:19 are written across many different languages and developed
6:22 in the open source community, and also led by many different companies
6:26 and AI developers.
6:27 We're seeing MCP compatible applications across web applications,
6:32 across desktop applications, and even agentic products as well.
6:35 Before we wrap up,
6:36 let's answer a couple of common questions you might be having about MCP.
6:40 These MCP servers that we talk about, from GitHub to Asana to Google Drive.
6:44 Who actually writes those?
6:45 Well, anyone can.
6:46 You yourself as a developer can build them,
6:49 or you can go ahead and use community adopted ones.
6:52 In the next few lessons, we'll see how MCP servers are built,
6:56 and we're going to build quite a few of our own.
6:57 You might think of MCP servers as very similar to working with APIs,
7:02 and in fact you're not totally off.
7:03 You can think of an MCP server as kind of like a gateway or a wrapper
7:07 on top of an API, where if you do not want to bother calling the API directly,
7:12 you can use natural language and let the MCP server handle that for you.
7:16 MCP servers support tool use,
7:18 but that's just one part of what MCP servers can do.
7:21 The servers give you functions and schemas available to you, but as we're going
7:25 to see in the next lesson, there's so much more that MCP provides.
7:29 So we answer the question why the Model Context Protocol?
7:32 We've seen a really nice demo for what it can do
7:34 with a very little amount of work.
7:36 And the next lesson we're going to start to explore how MCP works a bit
7:39 under the hood and introduce the idea of hosts and clients and servers,
7:43 and talk a little bit about some of the underlying
7:45 primitives in the protocol, like resources, tools and prompts.
7:49 See you then.
```
<img width="781" height="423" alt="image" src="https://github.com/user-attachments/assets/b1d1c628-963f-4c2e-a625-b7a9ad478878" />


<img width="710" height="456" alt="image" src="https://github.com/user-attachments/assets/4c430034-5352-4121-bc6c-e27373cf6212" />

<img width="836" height="401" alt="image" src="https://github.com/user-attachments/assets/4cc7e836-6b79-4800-9975-a4abcf0a5803" />

<img width="642" height="382" alt="image" src="https://github.com/user-attachments/assets/e3737377-cede-482f-a7a2-c1e8b4697928" />

<img width="800" height="357" alt="image" src="https://github.com/user-attachments/assets/6efa9c2f-aa4f-4b30-a0d8-94934668ec43" />

# architecture

<img width="832" height="377" alt="image" src="https://github.com/user-attachments/assets/157dad0a-a19e-492e-9722-a5477cc265d4" />

<img width="752" height="415" alt="image" src="https://github.com/user-attachments/assets/48c16c6f-7cbc-4479-9dc6-318319662c09" />

<img width="889" height="385" alt="image" src="https://github.com/user-attachments/assets/ca3ad732-e06f-4c71-a149-6b1493142e9a" />

<img width="873" height="408" alt="image" src="https://github.com/user-attachments/assets/b754bff6-e8e8-4686-b9fb-6b4a1d1f1052" />


<img width="873" height="391" alt="image" src="https://github.com/user-attachments/assets/45495e2b-933f-4250-a349-545c2fb04fd3" />



<img width="610" height="372" alt="image" src="https://github.com/user-attachments/assets/b180b6ac-fd9a-4f6f-a0b6-5a2d5831e4f2" />


<img width="964" height="390" alt="image" src="https://github.com/user-attachments/assets/bcfca170-1df0-448b-9084-f685ba6629b3" />

<img width="664" height="405" alt="image" src="https://github.com/user-attachments/assets/3b6f8f9c-4842-4c13-8007-fd5ad951b056" />

# 3
```
0:01 MCP is based on a client-server architecture.
0:05 In this lesson, we'll go through the features that MCP can provide
0:08 and how the communication between the client and the server takes place.
0:12 All right. Let's dive in.
0:14 So we previously spoke about why the Model Context Protocol
0:17 is so useful for building AI applications and connecting to external data sources.
0:22 Now let's dive a little bit deeper into the architecture behind MCP.
0:26 Similar to other protocols, MCP follows the client-server architecture,
0:31 where we have MCP clients that maintain a 1 to 1 connection with MCP servers.
0:36 The way these two communicate with each other is through messages
0:40 defined by the MCP itself.
0:43 These clients live inside of a host.
0:46 This could be something like Claude desktop or Claude AI.
0:50 The host is responsible for storing and maintaining
0:53 all of the clients and connections to MCP servers.
0:56 We'll see this in a little more depth.
0:58 Hosts are LLM applications that want to access data through MCP.
1:02 The servers are lightweight programs that expose the specific capabilities
1:07 through the protocol.
1:08 And very soon we're going to start building our own servers.
1:10 We'll then build our own clients as well as hosts that contain multiple clients.
1:15 The code for that is going to be a little bit more lower level.
1:17 But the goal here is really to understand the architecture.
1:21 And when you use tools like Claude Desktop or Cursor
1:24 or Windsurf, you have an idea of what's happening under the hood.
1:27 So how does it work?
1:28 Before we discuss the responsibilities of the client and the server,
1:32 let's dive into some of the primitives or fundamental pieces of the protocol.
1:36 Starting with tools.
1:37 If you're familiar with tool use, tools in MCP are going to look very similar.
1:42 Tools are functions that can be invoked by the client.
1:45 These tools allow for retrieving, searching,
1:47 sending messages, and updating database records.
1:50 Tools are usually meant for data that might require
1:53 something like a Post request or some kind of modification.
1:56 Resources are a bit more similar to a Get request.
1:59 Resources are read-only data or context that's exposed by the server.
2:03 Your application can choose whether to consume
2:06 or use these resources, but it doesn't necessarily have to bring it into context.
2:10 Examples of resources can include database records, API responses,
2:15 files, PDFs, and so on that you may have.
2:18 The third primitive we're going to explore, is a prompt template.
2:20 And prompt templates aim to achieve a very reasonable task,
2:25 which is to remove the burden of prompt engineering from the user.
2:28 You might have an MCP server whose job is to query things in Google
2:32 Drive and summarize and so on, but the user itself would need to write
2:37 the prompt necessary
2:38 to achieve all of those tasks in the most efficient way possible.
2:41 Instead of mandating that the user write the entire prompt
2:45 and figure out the best practices for prompt engineering,
2:47 prompt templates are predefined templates that live on the server
2:52 that the client can access and feed to the user if they so choose.
2:56 We're going to see in a few lessons how to build tools, resources,
2:59 and prompt templates both on the server and the client.
3:02 The client's job is to find resources and find tools.
3:06 The server's job is to expose that information to the client.
3:10 Now that we have an idea of some of these primitives: tools,
3:13 resources, prompts, let's go explore what this actually looks like.
3:16 I'm going to be using a host Claude Desktop, and I'm going to connect
3:20 to an MCP server for SQL Lite that exposes tools, resources, and prompts.
3:25 So let's take a look at that right here in Claude Desktop
3:27 I've connected to an MCP
3:29 server and I have tools at my disposal to work with SQLite.
3:33 We'll talk a bit about the configuration settings in a later lesson.
3:36 I wanted to show you what this looks like in action.
3:39 Once I connect to this MCP server, I can start talking to my data
3:43 in natural language.
3:44 So I'll ask right after that what tables do I have
3:48 and how many records are in each table.
3:52 This right here is Claude connecting to the Outside World.
3:56 We can see here we're going to be using a tool
3:58 from the SQL light server called List Tables.
4:02 You can see in the request there's no dynamic data being sent.
4:05 And I'll go ahead and allow this.
4:07 The ability to require a human in the loop
4:10 is based on the interface that the host develops.
4:13 So the server itself is simply sending back the tools.
4:16 The client is then
4:17 taking advantage of those tools and executing the data necessary.
4:21 We can see here for the number of records that we have
4:23 30 products, 30 users and zero orders.
4:26 So we can see the records that we have in this table.
4:28 What we can start to do now is something a little more interesting.
4:31 By taking advantage of tools like artifacts
4:33 and making this slightly more visually appealing.
4:36 So generate an interesting visualization
4:41 based on
4:43 the data in the products table.
4:48 You can imagine even with my spelling
4:49 mistake, we'll be able to query that information that we need.
4:52 So we'll go find the table.
4:53 We'll run the necessary query and fetch the data necessary.
4:57 We'll see here we're going to analyze this.
4:59 And it's going to tell us
5:00 many things are price but there are a few higher-priced items.
5:03 We're going to use the analysis tool to analyze this data.
5:06 What we're bringing in here is context to an AI application.
5:10 This could be Claude desktop.
5:11 This could be with any other model.
5:13 This could be in any other environment.
5:15 But through MCP we can build really interesting
5:17 applications right off the bat.
5:19 I'm making use of the artifacts feature in Claude
5:22 so that we can see a nice little visualization.
5:24 But the goal here is really to let your imagination carry you
5:27 where you can go with this.
5:28 Bringing in external data.
5:30 External systems allows you to easily create much
5:33 more interesting, compelling, and powerful applications.
5:36 We'll see here the code generated.
5:37 It's going to be a nice little visualization.
5:39 I have a distribution.
5:40 I have price versus quantity and so on.
5:42 And right after that,
5:43 I can take this data that I want and turn it into something meaningful.
5:46 We're doing this through tool use.
5:48 So the first primitive that we've explored
5:50 are the tools given to us by the MCP server.
5:53 Next, let's explore some other primitives.
5:55 I'm going to see here in SQLite that there is an MCP demo prompt.
6:00 This is a prompt template that is being sent from the server,
6:02 where all I have to do as the user is pass in some dynamic data.
6:06 So here we're demonstrating what we can do with this particular prompt.
6:10 This is a topic to see the database with initial data.
6:13 So let's go ahead and seed the database with some data around planets.
6:17 When I add this to the prompt we can see right off the bat
6:20 there is a text file that's generated with a prompt
6:23 that the server has given me. We can see right here
6:26 this is not something that I, as the user, have to write.
6:29 I just choose the dynamic data and then I go ahead and run that particular prompt.
6:33 What we're going to see here is this prompt in action.
6:35 And here this is going to generate a business problem and analyze
6:38 some data and set up information and so on.
6:41 But you can imagine giving your users much more battle
6:44 tested evaluated prompts so you don't have to do it yourself.
6:48 You'll see here we're going to set up some tables.
6:50 We're going to query.
6:51 We're going to populate
6:52 all kinds of actions we can take based on the prompt
6:55 and the tools that we have at our disposal.
6:57 So here you're seeing an example of tools and prompts being integrated together
7:01 to make AI applications far more powerful than they are out of the box.
7:05 In a few lessons, we're going to start making our own prompts,
7:08 our own resources, and our own tools to see how this happens under the hood.
7:12 As we go through, we can actually see that there is a data insight here,
7:16 a business insight memo that gets updated as we are constantly adding more data.
7:20 This is an example of a resource.
7:22 Resources are dynamic.
7:23 They can be updated as data changes in your application.
7:27 And instead of requiring tools to fetch this information,
7:30 we have data here that can constantly be updated.
7:33 I could ask to update the memo.
7:35 I could ask to update information inside based on new data that I've achieved.
7:39 So in this little example we've seen a host Claude Desktop.
7:43 We've seen a variety of tools from the SQLite MCP server,
7:47 and we've seen prompts and resources that allow us to perform
7:49 really powerful actions.
7:51 Now that we've seen what it looks like to use tools with MCP
7:55 servers, let's go ahead and talk about how you actually create these.
7:58 MCP provides software development kits for building servers and clients
8:02 in quite a few languages.
8:03 In this course, you'll be using the Python MCP SDK,
8:06 which makes it very easy to declare tools, resources, and prompts.
8:11 You can see here to declare a tool.
8:13 We decorate a function.
8:14 We pass in the necessary arguments
8:16 and return values so that the tool schema can be generated.
8:20 And then we return
8:21 what happens when that tool needs to be executed.
8:23 For resources, we allow the server to expose data to the client.
8:28 And that's done by specifying a URI
8:30 or a location where the client goes to find that data.
8:34 You can call this whatever you want, but you can imagine to return a list
8:37 of documents, this is a pretty good one.
8:39 If you're sending back a certain data format,
8:41 you can specify that with the main type.
8:43 You decorate a function which returns the data that you want
8:47 when that resource is accessed.
8:48 And you can do that for direct resources.
8:51 Or if you happen to have some kind of dynamic information or ID,
8:55 you can go ahead and use a templated resource, just like an F string in Python.
8:59 To give you an example of what an interface
9:01 might look like with a resource.
9:03 You can have a command line application where you use an @ sign to then fetch
9:07 all the documents that you need,
9:08 or for a templated resource, you can reference that directly and inject
9:12 that into a prompt or request that's coming in. With resources,
9:16 we don't need tools to fetch the data that we need.
9:18 The server simply sends the data back to the client,
9:21 and the application chooses to use that data or not.
9:24 Lastly, let's talk about prompts.
9:26 Just like you saw
9:27 with decorating tools and resources, we do the same thing with a prompt.
9:31 We give it a name and description,
9:33 and then a list of messages or text to return back. With prompts,
9:38 you define a set of user assistant messages
9:41 or just the text of a prompt that you need.
9:43 You can imagine a situation where a user might want to convert
9:46 some data to markdown, and while this is a fine prompt,
9:50 it might be a lot nicer if you gave them a thoroughly evaluated prompt instead.
9:54 So with prompts and prompt templates,
9:56 the idea is for these to be user controlled,
9:59 where a user chooses to not have to do all the prompt engineering themselves,
10:02 and use the quality ones provided by the server.
10:05 Now that we have an idea on some of the primitives, let's talk
10:08 a little bit about the communication between clients and servers.
10:11 When the client opens up a connection to the server,
10:14 there's an initialization process where a request is sent, a response is
10:18 sent back, and a notification is sent to confirm initialization.
10:22 Once that initialization appears, there's an exchange of messages that happen.
10:26 It's important to look at these steps because in the code
10:29 you're actually going to see methods like initialize.
10:32 So make sure you understand these ideas under the hood.
10:35 So when we start writing code
10:36 you can understand what's happening. In message exchanges,
10:39 clients can send requests to servers.
10:41 Servers can send requests
10:43 to clients, notifications can also be sent back and forth.
10:46 We'll talk a bit later on
10:48 about some of the other protocols, where servers can sample
10:51 or request information from clients, and notifications can be sent both ways.
10:55 Finally, at the end of communication, there's a termination of that connection.
11:00 As we talk a little bit
11:00 more about the connection and the way in which messages are sent back and forth.
11:05 It's important to understand another part of the Model Context Protocol,
11:09 and that is the idea of a transport.
11:10 And a transport handles the mechanics of how messages are sent back and forth
11:15 between the client and the server,
11:16 depending on how you're running your application.
11:19 You will choose one of these different transports.
11:22 You can also make your own if you would like. For servers running locally,
11:26 we're going to be using standard IO or standard input output.
11:29 When we start deploying servers remotely later on in the course, we have the choice
11:33 between using HTTP and server-side events
11:36 or using the Streamable HTTP transport.
11:40 As of this time of recording, Streamable HTTP
11:43 is not supported yet across all software development kits.
11:47 So we're going to be talking in depth about it.
11:48 But in our example we'll be using HTTP with server center events.
11:52 To give you a little bit of a distinction,
11:54 when you're using HTTP, which servers and events
11:57 you need to open up a stateful connection that maintains a back-and-forth
12:01 that's open.
12:02 For certain kinds of applications and deployments, or stateless deployments,
12:06 this does not suffice.
12:08 So in a newer version of the specification, the Streamable HTTP
12:12 transport allows for stateful connections as well as stateless.
12:16 To talk about our first transport standard, IO.
12:18 The process involves the client launching the server as a subprocess,
12:22 and the server
12:23 reading and writing alongside the client with standard in and standard out.
12:27 All of this is going to be abstracted away from us,
12:30 but it's important to understand when using standard IO
12:33 that this is most commonly what's done when running servers locally.
12:37 When we talk about the transports or remote servers, you'll see that
12:41 there are different transports based on different versions of the protocol.
12:44 The original transport for remote servers involved
12:47 using HTTP and server events for a stateful connection.
12:52 In a stateful connection, the client and the server are communicating
12:55 with each other with no closed connection between requests.
12:59 Data can be shared.
13:00 Data can be sent and remembered between different requests.
13:04 With the ability to introduce state. In server sent events,
13:07 the server is also able to send back events and messages back to the client.
13:12 While this can work for a variety of applications, many applications
13:16 when deployed are not stateful nor need to be stateful.
13:19 In fact, it is sometimes more efficient for scaling applications to have servers
13:23 that are ephemeral or stateless, where each connection and each request
13:29 is different and not remembered to support both stateful and stateless connections.
13:33 Updated versions of the protocol included a new transport called Streamable HTTP,
13:38 which allows for making use of HTTP with server events for stateful connections
13:44 or standard stateless connections with HTTP on its own.
13:48 Going
13:49 forward, the Streamable transport is what is going to be recommended and used so
13:53 that you can support stateless connections as well as stateful connections.
13:57 The way that this works is by using HTTP, get and Post requests to some endpoint.
14:02 In this case, we have /MCP to initialize the request
14:06 and the server returns a response.
14:08 If we want to opt into or upgrade to server-sent events, we can go ahead
14:13 and issue an optional Get request and send notifications back and forth.
14:16 Otherwise, we make Post requests and we issue responses.
14:20 In this lesson, you've seen quite a bit. From the architecture behind MCP,
14:24 with clients and servers and hosts to demos making use
14:28 of some of the most popular primitives like tools, prompts and resources.
14:32 You saw some of the different transports and mechanisms for sending data,
14:35 and now it's time for you to get your hands on some code.
14:38 In the next lesson, we're going to take a look
14:40 at some functionality and some tools that we'll be using.
14:43 And then we're going to start layering on MCP logic
14:46 to build our own servers and eventually clients and hosts.
14:50 See you then.
```


